{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c03844ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stagiaire\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import keyword\n",
    "import ast\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "\n",
    "from manage import jsonAttempts2data, jsonExercises2data\n",
    "from code2aes import Code2Aes\n",
    "from aes2vec import learnModel, inferVectors, read_corpus, data2cor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d22e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data importations\n",
    "NC1014 = jsonAttempts2data('Datasets/NewCaledonia_1014.json')\n",
    "NCExercises = jsonExercises2data('Datasets/NewCaledonia_exercises.json')\n",
    "NC5690 = jsonAttempts2data('Datasets/NewCaledonia_5690.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e582d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that maps the encoded exercise to its real name\n",
    "exercice_name_dict = {}\n",
    "list_exo = list(NCExercises.values())\n",
    "for exo in list_exo:\n",
    "    # key : encoded name, value : real name of exercise\n",
    "    exercice_name_dict[exo[\"exo_name\"]] = exo[\"funcname\"] \n",
    "list_exo = list(set(exercice_name_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec1bb87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the attemps' embedding\n",
    "embedding_data = list(np.load('Datasets/results.npy'))\n",
    "embedding_data_correction = list(np.load('Datasets/results_corr.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b22e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data trajectories\n",
    "\n",
    "with open('Datasets\\data_visualisation.pkl', 'rb') as fichier:\n",
    "    data_visualisation = pickle.load(fichier)\n",
    "trajec_code = data_visualisation[4]\n",
    "trajec = data_visualisation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de88ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_code(data, encoded = True):\n",
    " \n",
    "    \"\"\"\n",
    "    data : list of attemps\n",
    "    encoded : if exo name are encoded\n",
    "    Return a dictionary where the keys represent each student.\n",
    "    For each student, the corresponding value is a dictionary where:\n",
    "        - The keys are exercises\n",
    "        - The values are lists of attempts for each exercise\n",
    "    \"\"\"\n",
    "    codes = {}\n",
    "    for attemps in data:\n",
    "        user = attemps[\"user\"]\n",
    "        exercise = attemps[\"exercise_name\"]\n",
    "        if encoded:\n",
    "            exercise = exercice_name_dict[exercise]\n",
    "        if user not in codes:\n",
    "            codes[user] = {}\n",
    "        if exercise not in codes[user]:\n",
    "            codes[user][exercise] = []\n",
    "        codes[user][exercise].append(attemps[\"upload\"])\n",
    "    return codes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7259034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = get_source_code(NC5690)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "918f3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanShift_(data):\n",
    "    \"\"\"\n",
    "    Return : list of labels for each attemp\n",
    "    \"\"\"\n",
    "    mean_shift = MeanShift() \n",
    "    clusters = mean_shift.fit_predict(data)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf7cf529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(trajec, exercise):\n",
    "    \"\"\"\n",
    "    Return : list of labels for each attemp\n",
    "    \"\"\"\n",
    "    embbedings = trajec[exercise]\n",
    "    cluster = MeanShift_(embbedings)\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c0ee4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "want_clustering = False # Put at True if you want to do your own clustering\n",
    "if want_clustering:\n",
    "    warnings.filterwarnings('ignore')\n",
    "    cluster_exercise = {}\n",
    "    used = []\n",
    "    for i, correction in tqdm(enumerate(NCExercises)):\n",
    "        exercise = exercice_name_dict[correction]\n",
    "        if exercise not in used:\n",
    "            used.append(exercise)\n",
    "            cluster = clustering(trajec, exercise)\n",
    "            cluster_exercise[exercise] = cluster\n",
    "    with open('Datasets/cluster_meanshift.pkl', 'wb') as f:\n",
    "        pickle.dump(cluster_exercise, f)\n",
    "    \n",
    "else:\n",
    "    with open('Datasets/cluster_meanshift.pkl', 'rb') as f:\n",
    "        cluster_exercise = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3fdc243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_name_node(node):\n",
    "    \"\"\"\n",
    "    Get the name of the node in an AST\n",
    "    \"\"\"\n",
    "    name = node.__class__.__name__.lower()\n",
    "    if node == \"range\":\n",
    "        return node\n",
    "    else:\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "294dc9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's see an example of how our function work : \n",
      "\n",
      "\n",
      "Keyword node : functiondef\n",
      "Associated operation : nonetype\n",
      "\n",
      "Keyword node : if\n",
      "Associated operation : eq\n",
      "\n",
      "Keyword node : assign\n",
      "Associated operation : constant\n",
      "\n",
      "Keyword node : assign\n",
      "Associated operation : constant\n",
      "\n",
      "Keyword node : assign\n",
      "Associated operation : list\n",
      "\n",
      "Keyword node : assign\n",
      "Associated operation : constant\n",
      "\n",
      "Keyword node : for\n",
      "Associated operation : range\n",
      "\n",
      "Keyword node : if\n",
      "Associated operation : nonetype\n",
      "\n",
      "Keyword node : assign\n",
      "Associated operation : binop\n",
      "\n",
      "Keyword node : assign\n",
      "Associated operation : subscript\n",
      "\n",
      "Keyword node : if\n",
      "Associated operation : in\n",
      "\n",
      "Keyword node : assign\n",
      "Associated operation : binop\n",
      "\n",
      "Keyword node : if\n",
      "Associated operation : notin\n",
      "\n",
      "Keyword node : assign\n",
      "Associated operation : binop\n",
      "\n",
      "Keyword node : return\n",
      "Associated operation : nonetype\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NodeVisitor(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self.keywords = []\n",
    "        self.operations = []\n",
    "\n",
    "    def visit(self, node):\n",
    "        if isinstance(node, ast.stmt):\n",
    "            self.keywords.append(node)\n",
    "            self.operations.append(self.get_operation(node))\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def get_operation(self, node):\n",
    "        if isinstance(node, ast.If):\n",
    "            if isinstance(node.test, ast.Compare):\n",
    "                op = node.test.ops[0]\n",
    "                return op\n",
    "        if isinstance(node, ast.For):\n",
    "            if isinstance(node.iter, ast.Call) and isinstance(node.iter.func, ast.Name) and node.iter.func.id == 'range':\n",
    "                return \"range\"\n",
    "            elif isinstance(node.iter, ast.Str):\n",
    "                return \"str\"\n",
    "            else:\n",
    "                return node.iter\n",
    "        elif isinstance(node,ast.While):\n",
    "            return node.test\n",
    "        elif isinstance(node, ast.Assign):\n",
    "            if node.targets:\n",
    "                target = node.targets[0]\n",
    "                if hasattr(node, \"value\"):\n",
    "                    return node.value\n",
    "        else:\n",
    "            return None\n",
    "def get_ast_keywords_and_operations(code):\n",
    "    tree = ast.parse(code)\n",
    "    visitor = NodeVisitor()\n",
    "    visitor.visit(tree)\n",
    "    return visitor.keywords, visitor.operations\n",
    "\n",
    "print(\"Let's see an example of how our function work : \")\n",
    "print(\"\\n\")\n",
    "keywords, operations = get_ast_keywords_and_operations(codes[\"userdId_15\"][\"nbSyllabes\"][-3])\n",
    "\n",
    "for idx, keyword in enumerate(keywords):\n",
    "    print(f\"Keyword node : {find_name_node(keyword)}\")\n",
    "    print(f\"Associated operation : {find_name_node(operations[idx])}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc0dc3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attemps_by_cluster(trajec_code, labels_emb):\n",
    "    \"\"\"\n",
    "    codes : dictionary\n",
    "    labels_emb : dictionary\n",
    "    return : dictionary. Each key corresponds to an exercise.\n",
    "    Each exercise is a dictionary indicating which cluster it belongs to.\n",
    "    \"\"\"\n",
    "    attemps_by_cluster = {}\n",
    "    for exercise in labels_emb:\n",
    "        attemps_by_cluster[exercise] = {}\n",
    "        attemps = trajec_code[exercise]\n",
    "        labels = labels_emb[exercise]\n",
    "        if len(labels) != len(attemps):\n",
    "            print(len(labels),len(attemps))\n",
    "        for i, attemp in enumerate(attemps):\n",
    "            label = labels[i]\n",
    "            if label not in attemps_by_cluster[exercise]:\n",
    "                attemps_by_cluster[exercise][label] = []\n",
    "            attemps_by_cluster[exercise][label].append(attemp)\n",
    "    return attemps_by_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "006c50e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "attemps_by_cluster = get_attemps_by_cluster(trajec_code, cluster_exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a607bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyword_operation(attemps_by_cluster):\n",
    "    \"\"\"\n",
    "    attemps_by_cluster : dictionnary\n",
    "    Return : dictionnary of dictionnary for each exercise\n",
    "    Each dictonnary of exercise got as keys the cluster where the attemps belong and\n",
    "    as values the number of time the pair keyword operation is in the cluster\n",
    "    \"\"\"\n",
    "    keyword_operation = {}\n",
    "    for exercise in attemps_by_cluster:\n",
    "        keyword_operation[exercise] = {}\n",
    "        for cluster in attemps_by_cluster[exercise]:\n",
    "            if cluster not in keyword_operation[exercise]:\n",
    "                keyword_operation[exercise][cluster] = {}\n",
    "            attemps = attemps_by_cluster[exercise][cluster]\n",
    "            for attemp in attemps:   \n",
    "                keywords, operations = get_ast_keywords_and_operations(attemp)\n",
    "                for keyword, operation in zip(keywords,operations):\n",
    "                    keyword, operation = find_name_node(keyword), find_name_node(operation)\n",
    "                    if (keyword, operation) not in keyword_operation[exercise][cluster]:\n",
    "                        keyword_operation[exercise][cluster][(keyword,operation)] = 0\n",
    "                    keyword_operation[exercise][cluster][(keyword,operation)] += 1\n",
    "    return keyword_operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e548a41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<unknown>:6: SyntaxWarning: invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "keyword_operation = get_keyword_operation(attemps_by_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8c2555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyword_operation_exercise(keyword_operation):\n",
    "    \"\"\"\n",
    "    return a dictionnary of list of all the pair keyword operation that exist for each exercise\n",
    "    without consideration of the cluster\n",
    "    \"\"\"\n",
    "    keyword_ope = {}\n",
    "    for exercise in keyword_operation:\n",
    "        keyword_ope[exercise] = []\n",
    "        for cluster in keyword_operation[exercise]:\n",
    "            keyword_ope[exercise].append(keyword_operation[exercise][cluster])\n",
    "    return keyword_ope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa9172ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_ope = get_keyword_operation_exercise(keyword_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d077bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_keywords(keywords_operation1, keywords_operation2):\n",
    "    \"\"\"\n",
    "    Methode used to compare two sets of pair keyword operation\n",
    "    They compare the difference between these two sets\n",
    "    \"\"\"\n",
    "    set_keywords1, set_keywords2 = set(keywords_operation1), set(keywords_operation2.keys())\n",
    "    set_compare = set_keywords1 - set_keywords2\n",
    "    return set_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf2ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ba2f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caracterisation_cluster_(keyword_ope):\n",
    "    \"\"\"\n",
    "    - keyword_ope : dictionnary\n",
    "    Return a dictionnary with exercise as keys\n",
    "    For each exercise, we got a set of what pair define the cluster\n",
    "    \"\"\"\n",
    "    caracterisation_cluster = {}\n",
    "    for exercise in keyword_ope:\n",
    "        caracterisation_cluster[exercise] = []\n",
    "        for j, key_ope in enumerate(keyword_ope[exercise]):\n",
    "            unique_key_ope = set(key_ope.keys())\n",
    "            for i in range(j+1,len(keyword_ope[exercise])):\n",
    "                set_key_ope = compare_keywords(unique_key_ope, keyword_ope[exercise][i])\n",
    "            caracterisation_cluster[exercise].append(set_key_ope)\n",
    "    return caracterisation_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "619c0b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "caracterisation_cluster =  caracterisation_cluster_(keyword_ope)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde2209a",
   "metadata": {},
   "source": [
    "Example for an exericise : \"nbSyllabes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3973f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For cluster 0, the keywords/operations that characterize it the most:\n",
      "{('augassign', 'nonetype'), ('for', 'range')}\n",
      "\n",
      "\n",
      "For cluster 1, the keywords/operations that characterize it the most:\n",
      "{('assign', 'subscript'), ('assign', 'list'), ('if', 'notin'), ('for', 'range')}\n",
      "\n",
      "\n",
      "For cluster 2, the keywords/operations that characterize it the most:\n",
      "{('augassign', 'nonetype'), ('if', 'notin'), ('for', 'range')}\n",
      "\n",
      "\n",
      "For cluster 3, the keywords/operations that characterize it the most:\n",
      "{('augassign', 'nonetype'), ('if', 'notin'), ('for', 'range')}\n",
      "\n",
      "\n",
      "For cluster 4, the keywords/operations that characterize it the most:\n",
      "{('augassign', 'nonetype'), ('if', 'notin'), ('for', 'range')}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, set_clus in enumerate(caracterisation_cluster[\"nbSyllabes\"]):\n",
    "    print(f\"For cluster {i}, the keywords/operations that characterize it the most:\")\n",
    "    print(set_clus)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ccc03",
   "metadata": {},
   "source": [
    "# Caracterisation of small trajectory\n",
    "For the n-th attemp of an student in a exercise, a small trajectory is define by the change between the n-th and n+1-th attemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8611192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_keyop(keywords1, operations1, keywords2, operations2):\n",
    "        key_op1,key_op2 = [], []\n",
    "        for idx, keyword in enumerate(keywords1):\n",
    "            keyword = find_name_node(keyword)\n",
    "            operation = find_name_node(operations1[idx])\n",
    "            key_op1.append((keyword,operation))\n",
    "        for idx, keyword in enumerate(keywords2):\n",
    "            keyword = find_name_node(keyword)\n",
    "            operation = find_name_node(operations2[idx])\n",
    "            key_op2.append((keyword,operation))\n",
    "        key_op1, key_op2 = set(key_op1), set(key_op2)\n",
    "        return key_op1, key_op2\n",
    "    \n",
    "def caracterisation(keywords1, operations1, keywords2, operations2):\n",
    "        key_op1, key_op2 = get_set_keyop(keywords1, operations1, keywords2, operations2)\n",
    "        carac_traj_rajout = key_op2 - key_op1\n",
    "        carac_traj_suppr = key_op1 - key_op2\n",
    "        carac_traj = {\"Add \" : carac_traj_rajout, \"Delete\" : carac_traj_suppr}\n",
    "        return carac_traj\n",
    "\n",
    "\n",
    "\n",
    "def caracterise_small_trajectory(student,exercise, codes):\n",
    "    for i in range(len(codes[student][exercise])-1):\n",
    "        keywords1, operations1 = get_ast_keywords_and_operations(codes[student][exercise][i])\n",
    "        keywords2, operations2 = get_ast_keywords_and_operations(codes[student][exercise][i+1])\n",
    "        print(f\"Trajectory number {i}\")\n",
    "        print(caracterisation(keywords1, operations1, keywords2, operations2))\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab3909a",
   "metadata": {},
   "source": [
    "For example, student 15 and exercise nbSyllabes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "701eea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory number 0\n",
      "{'Add ': {('if', 'notin')}, 'Delete': set()}\n",
      "\n",
      "Trajectory number 1\n",
      "{'Add ': set(), 'Delete': {('if', 'notin')}}\n",
      "\n",
      "Trajectory number 2\n",
      "{'Add ': {('if', 'notin')}, 'Delete': {('assign', 'subscript')}}\n",
      "\n",
      "Trajectory number 3\n",
      "{'Add ': {('assign', 'subscript')}, 'Delete': {('if', 'notin')}}\n",
      "\n",
      "Trajectory number 4\n",
      "{'Add ': {('if', 'notin')}, 'Delete': set()}\n",
      "\n",
      "Trajectory number 5\n",
      "{'Add ': set(), 'Delete': set()}\n",
      "\n",
      "Trajectory number 6\n",
      "{'Add ': set(), 'Delete': set()}\n",
      "\n",
      "Trajectory number 7\n",
      "{'Add ': set(), 'Delete': {('if', 'eq'), ('if', 'notin'), ('assign', 'subscript'), ('if', 'in'), ('assign', 'list')}}\n",
      "\n",
      "Trajectory number 8\n",
      "{'Add ': {('if', 'eq'), ('if', 'notin'), ('assign', 'subscript'), ('if', 'in'), ('assign', 'list')}, 'Delete': set()}\n",
      "\n",
      "Trajectory number 9\n",
      "{'Add ': set(), 'Delete': set()}\n",
      "\n",
      "Trajectory number 10\n",
      "{'Add ': set(), 'Delete': {('assign', 'subscript'), ('if', 'eq'), ('if', 'in'), ('assign', 'list')}}\n",
      "\n",
      "Trajectory number 11\n",
      "{'Add ': set(), 'Delete': set()}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "caracterise_small_trajectory(\"userdId_15\",\"nbSyllabes\",codes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
